{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_neural_nets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "O2q5RRCKqYaU",
        "vvT2jDWjrKew"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwng09/GoogleMachineLearningExercises/blob/master/intro_to_neural_nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV16J6oUY-HN",
        "colab_type": "text"
      },
      "source": [
        "# Intro to Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wIcUFLSKNdx",
        "colab_type": "text"
      },
      "source": [
        "**Learning Objectives:**\n",
        "  * Define a neural network (NN) and its hidden layers using the TensorFlow `DNNRegressor` class\n",
        "  * Train a neural network to learn nonlinearities in a dataset and achieve better performance than a linear regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZZ7f7prKNdy",
        "colab_type": "text"
      },
      "source": [
        "In the previous exercises, we used synthetic features to help our model incorporate nonlinearities.\n",
        "\n",
        "One important set of nonlinearities was around latitude and longitude, but there may be others.\n",
        "\n",
        "We'll also switch back, for now, to a standard regression task, rather than the logistic regression task from the previous exercise. That is, we'll be predicting `median_house_value` directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2kqX6VZTHUy",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, let's load and prepare the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGOM1TUiKNdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "\n",
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I8E2qhyKNd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_features(california_housing_dataframe):\n",
        "  \"\"\"Prepares input features from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the features to be used for the model, including\n",
        "    synthetic features.\n",
        "  \"\"\"\n",
        "  selected_features = california_housing_dataframe[\n",
        "    [\"latitude\",\n",
        "     \"longitude\",\n",
        "     \"housing_median_age\",\n",
        "     \"total_rooms\",\n",
        "     \"total_bedrooms\",\n",
        "     \"population\",\n",
        "     \"households\",\n",
        "     \"median_income\"]]\n",
        "  processed_features = selected_features.copy()\n",
        "  # Create a synthetic feature.\n",
        "  processed_features[\"rooms_per_person\"] = (\n",
        "    california_housing_dataframe[\"total_rooms\"] /\n",
        "    california_housing_dataframe[\"population\"])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(california_housing_dataframe):\n",
        "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the target feature.\n",
        "  \"\"\"\n",
        "  output_targets = pd.DataFrame()\n",
        "  # Scale the target to be in units of thousands of dollars.\n",
        "  output_targets[\"median_house_value\"] = (\n",
        "    california_housing_dataframe[\"median_house_value\"] / 1000.0)\n",
        "  return output_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQzcj2B1T5dA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d8dd35b-3d1b-4d69-e1d3-f263467b8a54"
      },
      "source": [
        "# Choose the first 12000 (out of 17000) examples for training.\n",
        "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
        "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
        "\n",
        "# Choose the last 5000 (out of 17000) examples for validation.\n",
        "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
        "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))\n",
        "\n",
        "# Double-check that we've done the right thing.\n",
        "print(\"Training examples summary:\")\n",
        "display.display(training_examples.describe())\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(validation_examples.describe())\n",
        "\n",
        "print(\"Training targets summary:\")\n",
        "display.display(training_targets.describe())\n",
        "print(\"Validation targets summary:\")\n",
        "display.display(validation_targets.describe())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.5</td>\n",
              "      <td>2650.9</td>\n",
              "      <td>539.3</td>\n",
              "      <td>1436.0</td>\n",
              "      <td>501.6</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>2202.7</td>\n",
              "      <td>423.5</td>\n",
              "      <td>1180.3</td>\n",
              "      <td>386.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1470.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>794.8</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2128.5</td>\n",
              "      <td>433.0</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>408.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3159.2</td>\n",
              "      <td>647.0</td>\n",
              "      <td>1721.0</td>\n",
              "      <td>604.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>32627.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>41.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       latitude  longitude  ...  median_income  rooms_per_person\n",
              "count   12000.0    12000.0  ...        12000.0           12000.0\n",
              "mean       35.6     -119.6  ...            3.9               2.0\n",
              "std         2.1        2.0  ...            1.9               1.0\n",
              "min        32.5     -124.3  ...            0.5               0.0\n",
              "25%        33.9     -121.8  ...            2.6               1.5\n",
              "50%        34.2     -118.5  ...            3.6               1.9\n",
              "75%        37.7     -118.0  ...            4.8               2.3\n",
              "max        42.0     -114.3  ...           15.0              41.3\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.8</td>\n",
              "      <td>2626.2</td>\n",
              "      <td>539.7</td>\n",
              "      <td>1414.1</td>\n",
              "      <td>500.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.8</td>\n",
              "      <td>2124.5</td>\n",
              "      <td>416.6</td>\n",
              "      <td>1065.9</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1441.8</td>\n",
              "      <td>296.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2126.0</td>\n",
              "      <td>435.5</td>\n",
              "      <td>1162.5</td>\n",
              "      <td>410.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3138.2</td>\n",
              "      <td>653.2</td>\n",
              "      <td>1720.2</td>\n",
              "      <td>607.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.5</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>5471.0</td>\n",
              "      <td>16122.0</td>\n",
              "      <td>5189.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       latitude  longitude  ...  median_income  rooms_per_person\n",
              "count    5000.0     5000.0  ...         5000.0            5000.0\n",
              "mean       35.6     -119.6  ...            3.9               2.0\n",
              "std         2.2        2.0  ...            1.9               1.5\n",
              "min        32.5     -124.3  ...            0.5               0.1\n",
              "25%        33.9     -121.8  ...            2.5               1.5\n",
              "50%        34.2     -118.5  ...            3.5               1.9\n",
              "75%        37.7     -118.0  ...            4.7               2.3\n",
              "max        42.0     -114.5  ...           15.0              55.2\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>206.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>115.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>119.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>180.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>265.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       median_house_value\n",
              "count             12000.0\n",
              "mean                206.9\n",
              "std                 115.3\n",
              "min                  15.0\n",
              "25%                 119.8\n",
              "50%                 180.9\n",
              "75%                 265.2\n",
              "max                 500.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>208.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>117.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>118.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>179.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>264.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       median_house_value\n",
              "count              5000.0\n",
              "mean                208.3\n",
              "std                 117.7\n",
              "min                  15.0\n",
              "25%                 118.9\n",
              "50%                 179.3\n",
              "75%                 264.4\n",
              "max                 500.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWq0xecNKNeG",
        "colab_type": "text"
      },
      "source": [
        "## Building a Neural Network\n",
        "\n",
        "The NN is defined by the [DNNRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor) class.\n",
        "\n",
        "Use **`hidden_units`** to define the structure of the NN.  The `hidden_units` argument provides a list of ints, where each int corresponds to a hidden layer and indicates the number of nodes in it.  For example, consider the following assignment:\n",
        "\n",
        "`hidden_units=[3,10]`\n",
        "\n",
        "The preceding assignment specifies a neural net with two hidden layers:\n",
        "\n",
        "* The first hidden layer contains 3 nodes.\n",
        "* The second hidden layer contains 10 nodes.\n",
        "\n",
        "If we wanted to add more layers, we'd add more ints to the list. For example, `hidden_units=[10,20,30,40]` would create four layers with ten, twenty, thirty, and forty units, respectively.\n",
        "\n",
        "By default, all hidden layers will use ReLu activation and will be fully connected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni0S6zHcTb04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_feature_columns(input_features):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Args:\n",
        "    input_features: The names of the numerical input features to use.\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  return set([tf.feature_column.numeric_column(my_feature)\n",
        "              for my_feature in input_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvCqgNdzpaFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a neural net regression model.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                             \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U52Ychv9KNeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_nn_regression_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a neural network regression model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `DNNRegressor` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a DNNRegressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  dnn_regressor = tf.estimator.DNNRegressor(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "  )\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  training_rmse = []\n",
        "  validation_rmse = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    dnn_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.\n",
        "    training_predictions = dnn_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    \n",
        "    validation_predictions = dnn_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    # Compute training and validation loss.\n",
        "    training_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_rmse.append(training_root_mean_squared_error)\n",
        "    validation_rmse.append(validation_root_mean_squared_error)\n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse, label=\"training\")\n",
        "  plt.plot(validation_rmse, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  print(\"Final RMSE (on training data):   %0.2f\" % training_root_mean_squared_error)\n",
        "  print(\"Final RMSE (on validation data): %0.2f\" % validation_root_mean_squared_error)\n",
        "\n",
        "  return dnn_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QhdcCy-Y8QR",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Train a NN Model\n",
        "\n",
        "**Adjust hyperparameters, aiming to drop RMSE below 110.**\n",
        "\n",
        "Run the following block to train a NN model.  \n",
        "\n",
        "Recall that in the linear regression exercise with many features, an RMSE of 110 or so was pretty good.  We'll aim to beat that.\n",
        "\n",
        "Your task here is to modify various learning settings to improve accuracy on validation data.\n",
        "\n",
        "Overfitting is a real potential hazard for NNs.  You can look at the gap between loss on training data and loss on validation data to help judge if your model is starting to overfit. If the gap starts to grow, that is usually a sure sign of overfitting.\n",
        "\n",
        "Because of the number of different possible settings, it's strongly recommended that you take notes on each trial to help guide your development process.\n",
        "\n",
        "Also, when you get a good setting, try running it multiple times and see how repeatable your result is. NN weights are typically initialized to small random values, so you should see differences from run to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXmtSW1yKNeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "d698f251-19bb-4e75-fc61-b803bc2d633f"
      },
      "source": [
        "dnn_regressor = train_nn_regression_model(\n",
        "    learning_rate=0.001,\n",
        "    steps=2000,\n",
        "    batch_size=100,\n",
        "    hidden_units=[10, 10],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 167.55\n",
            "  period 01 : 164.36\n",
            "  period 02 : 161.65\n",
            "  period 03 : 158.72\n",
            "  period 04 : 155.33\n",
            "  period 05 : 150.33\n",
            "  period 06 : 150.73\n",
            "  period 07 : 137.09\n",
            "  period 08 : 127.04\n",
            "  period 09 : 120.00\n",
            "Model training finished.\n",
            "Final RMSE (on training data):   120.00\n",
            "Final RMSE (on validation data): 121.64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEYCAYAAADxmJlCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVG7NKOIiKhdmlFERNTuJ1dJ/jeYaI+oAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2q5RRCKqYaU",
        "colab_type": "text"
      },
      "source": [
        "### Solution\n",
        "\n",
        "Click below to see a possible solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2Yd5VfrqcC3",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** This selection of parameters is somewhat arbitrary. Here we've tried combinations that are increasingly complex, combined with training for longer, until the error falls below our objective (training is nondeterministic, so results may fluctuate a bit each time you run the solution). This may not be the best combination; others may attain an even lower RMSE. If your aim is to find the model that can attain the best error, then you'll want to use a more rigorous process, like a parameter search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjkpSqmxqnSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f56142a1-084e-44ac-f9c5-bfc8410d9050"
      },
      "source": [
        "dnn_regressor = train_nn_regression_model(\n",
        "    learning_rate=0.001,\n",
        "    steps=2000,\n",
        "    batch_size=100,\n",
        "    hidden_units=[10, 10],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 165.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cb61b7baeeb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     validation_targets=validation_targets)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-9a6da3fc099e>\u001b[0m in \u001b[0;36mtrain_nn_regression_model\u001b[0;34m(learning_rate, steps, batch_size, hidden_units, training_examples, training_targets, validation_examples, validation_targets)\u001b[0m\n\u001b[1;32m     67\u001b[0m     dnn_regressor.train(\n\u001b[1;32m     68\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Take a break and compute predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1194\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1488\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_creation_timeout_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1491\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    582\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \"\"\"\n\u001b[1;32m   1206\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m     return self._get_session_manager().prepare_session(\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m           sharded=True)\n\u001b[1;32m    236\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           build_restore=build_restore)\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m           restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n\u001b[0;32m--> 502\u001b[0;31m                                                   restore_sequentially, reshape)\n\u001b[0m\u001b[1;32m    503\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_AddShardedRestoreOps\u001b[0;34m(self, filename_tensor, per_device, restore_sequentially, reshape)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0mpreferred_shard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 name=\"restore_shard\"))\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msharded_restores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"restore_all\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_AddRestoreOps\u001b[0;34m(self, filename_tensor, saveables, restore_sequentially, reshape, preferred_shard, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \"\"\"\n\u001b[1;32m    327\u001b[0m     all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n\u001b[0;32m--> 328\u001b[0;31m                                     restore_sequentially)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0massign_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mbulk_restore\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;31m# Load all tensors onto CPU 0 for compatibility with existing code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;34m\"RestoreV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m                      \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1696\u001b[0;31m                      name=name)\n\u001b[0m\u001b[1;32m   1697\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    529\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    269\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    270\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 271\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    272\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m   \u001b[0;31m# Helper functions to create operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3301\u001b[0;31m   @deprecated_args(None,\n\u001b[0m\u001b[1;32m   3302\u001b[0m                    \u001b[0;34m\"Shapes are always computed; don't use the compute_shapes \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3303\u001b[0m                    \"as it has no effect.\", \"compute_shapes\")\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6diezCSeH4Y",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Evaluate on Test Data\n",
        "\n",
        "**Confirm that your validation performance results hold up on test data.**\n",
        "\n",
        "Once you have a model you're happy with, evaluate it on test data to compare that to validation performance.\n",
        "\n",
        "Reminder, the test data set is located [here](https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icEJIl5Vp51r",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "755cb910-3482-44ba-cfcb-d0948d357a98"
      },
      "source": [
        "california_housing_test_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\", sep=\",\")\n",
        "\n",
        "test_examples = preprocess_features(california_housing_test_data)\n",
        "test_targets = preprocess_targets(california_housing_test_data)\n",
        "\n",
        "predict_test_input_fn = lambda: my_input_fn(test_examples, test_targets, shuffle=False, num_epochs=1)\n",
        "\n",
        "test_predictions = dnn_regressor.predict(predict_test_input_fn)\n",
        "test_predictions = np.array([item['predictions'][0] for item in test_predictions])\n",
        "\n",
        "test_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(test_predictions, test_targets))\n",
        "\n",
        "print(\"Final RMSE (on test data): %0.2f\" % test_root_mean_squared_error)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final RMSE (on test data): 119.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvT2jDWjrKew",
        "colab_type": "text"
      },
      "source": [
        "### Solution\n",
        "\n",
        "Click below to see a possible solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyDh7Qy6rQb0",
        "colab_type": "text"
      },
      "source": [
        "Similar to what the code at the top does, we just need to load the appropriate data file, preprocess it and call predict and mean_squared_error.\n",
        "\n",
        "Note that we don't have to randomize the test data, since we will use all records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhb0CtdvrWZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec1cb811-8cd1-4d9e-aa1b-f018df952cbc"
      },
      "source": [
        "california_housing_test_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\", sep=\",\")\n",
        "\n",
        "test_examples = preprocess_features(california_housing_test_data)\n",
        "test_targets = preprocess_targets(california_housing_test_data)\n",
        "\n",
        "predict_testing_input_fn = lambda: my_input_fn(test_examples, \n",
        "                                               test_targets[\"median_house_value\"], \n",
        "                                               num_epochs=1, \n",
        "                                               shuffle=False)\n",
        "\n",
        "test_predictions = dnn_regressor.predict(input_fn=predict_testing_input_fn)\n",
        "test_predictions = np.array([item['predictions'][0] for item in test_predictions])\n",
        "\n",
        "root_mean_squared_error = math.sqrt(\n",
        "    metrics.mean_squared_error(test_predictions, test_targets))\n",
        "\n",
        "print(\"Final RMSE (on test data): %0.2f\" % root_mean_squared_error)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final RMSE (on test data): 119.53\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}